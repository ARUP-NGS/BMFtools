#!/usr/bin/env python

# Standard library imports
import datetime
import logging
import os
import sys
import uuid
import cython
from sys import stderr

# BMFTools python imports
from utilBMF.HTSUtils import printlog as pl, TrimExt
from MawCluster.BCBam import pairedBarcodeTagging, singleBarcodeTagging
from utilBMF.ArgumentSketcher import ArgumentSketcher
from utilBMF.GlobalReporting import SampleMetrics, ReviewDirComponents
from utilBMF.QC import GetAllQCMetrics
from BMFMain import Workflow as wf

from utilBMF.ErrorHandling import ThisIsHKMadness

global ReferenceDict

"""
bmftools contains various utilities for barcoded reads and for
somatic variant calling. Written to be similar in form to bcftools
and samtools.
"""

#  warnings.filterwarnings('error')


def main():
    import argparse
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest="bmfsuites")
    PipeParser = subparsers.add_parser(
        "pipetagbam",
        description="Tags a BAM, taking sam/bam input/output.")
    PipeParser.add_argument(
        "compression",
        help=("First letter determines compression of input."
              "Second letter determines compression of output."
              " (s/b for sam/bam). Add u to emit"
              " uncompressed BAM"))
    PEP8Parser = subparsers.add_parser(
        "pep8",
        description="Command for applying modified PEP8 to this code base.")
    MergePairedAlignmentsParser = subparsers.add_parser(
        "mpa",
        description="Merge duplex read read pairs into a single record each.")
    MainSubparser = subparsers.add_parser(
        "main", description="Run a full pipeline analysis.")
    BedCovParser = subparsers.add_parser(
        "bedcov", description="Calls FastDepthOfCoverage.")
    alignTagBamParser = subparsers.add_parser(
        "aligntagbam", description=("Performs alignment and sam tagging of"
                                    " consolidated fastq files to generate "
                                    "a tagged bam."))
    TagBamParser = subparsers.add_parser(
        "tagbam", description=("Tag a BAM file with appropriate information"
                               " from merged fastq files."))
    RescueShadingParser = subparsers.add_parser(
        "rsq", description="Rescue fastq shading.")
    versionParser = subparsers.add_parser(
        "v", description="Outputs version of BMFTools.")
    versionParser.add_argument(
        "--conf", help="Path to config file, only for compatibility.")
    InputQtyParser = subparsers.add_parser(
        "qty",
        description=("Calculates the quantity of input DNA needed to reach "
                     "a given mean PCR redundancy and a given amount of "
                     "sequencing power."))
    PSNVParser = subparsers.add_parser(
        "psnv", description="Parallel SNV calls.")
    PSNVParser.add_argument(
        "--conf",
        help="Config file to hold this so we don't have to specify.",
        type=str)
    PSNVParser.add_argument(
        "--threads",
        help="Number of threads.",
        type=int)
    PSNVParser.add_argument(
        "-o",
        "--outVCF",
        help="Output VCF File.",
        default=None,
        metavar="OutputVCF")
    PSNVParser.add_argument("inBAM",
                            help="Input BAM, Coordinate-sorted and indexed, "
                            "with BMF Tags included. bmftools runs on unflat"
                            "tened BAMs, but the results are not reliable be"
                            "cause this program assumes as much.",
                            type=str)
    VCFCmpParser = subparsers.add_parser(
        "vcfcmp", description="Compares VCF files.")
    VCFStatsParser = subparsers.add_parser("vcfstats",
                                           description="Gets counts and"
                                           " frequencies for all SNV tr"
                                           "ansitions.")
    DMultiPlexParser = subparsers.add_parser("dmp",
                                             description="Marks, combines, and"
                                             " processes a dataset of fastqs f"
                                             "or further analysis.")
    SNVParser = subparsers.add_parser("snv", description="Call SNVs. Assumes "
                                      "that reads have been collapsed from a "
                                      "family size of at least 2")
    SVParser = subparsers.add_parser("sv",
                                     description="Call structural variants. R"
                                     "equires an Input BAM, coordinate-sorted"
                                     " and indexed, with BMF SV Tags included"
                                     ", and a BED File.")
    SMAParser = subparsers.add_parser(
        "sma",
        description="Tool for splitting a VCF File with multiple alts per"
        " line into a VCF where each line has a unique alt.")
    GetUniqueKmerBedParser = subparsers.add_parser(
        "getuniquekmersbed",
        description=("Tool for selecting kmers which are unique identifiers "
                     "for a region of interest for assembly and produces a"
                     "bed file covering these regions."))
    SNVParser.add_argument("inBAM",
                           help="Input BAM, Coordinate-sorted and indexed, "
                           "with BMF Tags included. bmftools runs on unflat"
                           "tened BAMs, but the results are not reliable be"
                           "cause this program assumes as much.")
    SNVParser.add_argument(
        "--bed",
        "-b",
        help="Full path to bed file.",
        default=None,
        metavar="bedpath")
    SNVParser.add_argument(
        "-o",
        "--outVCF",
        help="Output VCF File.",
        default=None,
        metavar="OutputVCF")
    SNVParser.add_argument(
        "--minBQ",
        help="Minimum Base Quality to consider",
        default=None,
        type=int)
    SNVParser.add_argument(
        "--minMQ",
        help="Minimum Mapping Quality to consider",
        default=None,
        type=int)
    SNVParser.add_argument(
        "--MaxPValue",
        "-p",
        help="Maximum P value to consider, in e notation.",
        type=float,
        default=None)
    SNVParser.add_argument(
        "--keepConsensus",
        "-k",
        default=None)
    SNVParser.add_argument(
        "--logfile",
        help="Name for logfile.",
        default=None)
    SNVParser.add_argument(
        "-r",
        "--ref",
        help="Provide reference fasta.",
        default=None)
    SNVParser.add_argument("--minFA", help="Minimum family agreed on base.",
                           default=None, type=int)
    SNVParser.add_argument(
        "--conf",
        help="Config file to hold this so we don't have to specify.",
        type=str)
    SNVParser.add_argument(
        "--analysisTag", type=str,
        help=("Tag to append to the output VCF before the file extension."
              "Used to delineate analysis pipelines."))
    SNVParser.add_argument(
        "--is-slave",
        help="Whether or not SNVCrawler is slave instance.",
        action="store_true")
    SNVParser.add_argument(
        "--minFracAgreed",
        help=("Minimum fraction of reads in family to agree on a base call "
              "for inclusion in variant calling."),
        type=float)
    VCFStatsParser.add_argument(
        "inVCF",
        help="Input VCF, as created by SNVCrawler.")
    DMultiPlexParser.add_argument(
        "inFqs",
        nargs="+",
        help="Input Fastq Files")
    DMultiPlexParser.add_argument(
        "-i",
        "--indexFq",
        metavar="indexFastq",
        help="Index Fastq",
        required=True)
    DMultiPlexParser.add_argument(
        "-f",
        "--p5Seq",
        metavar="primer5Seq",
        help=("5' primer sequence used by cutadapt (defaults to 'default', "
              "which will run cutadapt to only trim the 3' primer sequence, "
              "if given)"))
    DMultiPlexParser.add_argument(
        "-t",
        "--p3Seq",
        metavar="primer3Seq",
        help=("3' primer sequence used by cutadapt (defaults to 'default', "
              "which will not run cutadapt)"))
    DMultiPlexParser.add_argument(
        "-r", "--rescue", action="store_true",
        help=("Flag to perform barcode rescue with default rescue parameters "
              "for experiments with very low library diversity. Currently "
              "only supported for paired-end reads."))
    DMultiPlexParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmftoo"
                        "ls_helper. Any command-line arguments override this "
                        "config file as well."))
    alignTagBamParser.add_argument(
        "inFqs",
        nargs="+",
        help="Input Fastq Files")
    alignTagBamParser.add_argument(
        "-b",
        "--bed",
        metavar="bed",
        help=("Bed file not used in the alignment but used in the REalignment"
              " and MawCluster.SVUtils's GetSVRelevantRecordsPaired"))
    alignTagBamParser.add_argument(
        "-r",
        "--ref",
        metavar="ref",
        help="Reference FASTA to align fastqs to")
    alignTagBamParser.add_argument(
        "-a",
        "--aligner",
        metavar="aligner",
        help="Aligner program (e.g. bwa 'mem' or bwa 'aln')")
    alignTagBamParser.add_argument(
        "-g",
        "--realigner",
        metavar="realigner",
        help="Realigner program (e.g. abra or gatk)")
    alignTagBamParser.add_argument(
        "-p", "--gatkpath",
        metavar="gatk",
        help="Path to the GATK Jar")
    alignTagBamParser.add_argument(
        "-t",
        "--abrapath",
        metavar="abrapath",
        help="Path to the abra realigner program")
    alignTagBamParser.add_argument(
        "-l",
        "--readlength",
        metavar="readlength",
        help="Read length (for abra.KmerSizeEvaluator program",
        type=int)
    alignTagBamParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmftoo"
                        "ls_helper. Any command-line arguments override this "
                        "config file as well."))
    TagBamParser.add_argument(
        "inBAM",
        metavar="inBAM",
        help="Untagged Bam, name-sorted")
    TagBamParser.add_argument(
        "--fastq",
        "-f",
        metavar="InFastqs",
        nargs="+",
        help="Tagged, Merged Fastq File(s)")
    TagBamParser.add_argument(
        "-o", "--outfile",
        help=("Path to output file. If not set, defaults to variation "
              "on input bam."),
        type=str)
    TagBamParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmftoo"
                        "ls_helper. Any command-line arguments override this "
                        "config file as well."))
    SVParser.add_argument(
        'bam',
        help=("Coordinate-Sorted, Indexed Bam File"),
        )
    SVParser.add_argument(
        "-b",
        "--bed",
        help="Path to bedfile.",
        )
    SVParser.add_argument(
        "--minMQ",
        "-m",
        help="Minimum mapping quality for inclusion. Default: 0.",
        type=int)
    SVParser.add_argument(
        "--minBQ",
        help="Minimum base quality for inclusion. Default: 0.",
        type=int)
    SVParser.add_argument(
        "-o",
        "--outTsv",
        help="Output tsv",
        )
    SVParser.add_argument(
        "--minPileupLen",
        "-l",
        help="Length of interval to be considered for call.",
        type=int)
    SVParser.add_argument(
        "--minClustDepth",
        "-d",
        type=int,
        help="Minimum depth for a cluster to be considered for call.")
    SVParser.add_argument(
        "--ref",
        "-r",
        help="Path to reference index.",
        required=True)
    SVParser.add_argument("--insert-distance",
                          "-i",
                          help="Maximum difference between edit distances"
                          " for clustering families together")
    SVParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmftoo"
                        "ls_helper. Any command-line arguments override this "
                        "config file as well."))
    SMAParser.add_argument(
        "inVCF",
        help="Input VCF", type=str)
    SMAParser.add_argument(
        "--outVCF",
        "-o",
        help="Output VCF. If unset, defaults to a modified form of the input.")
    SMAParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmfto"
                        "ols_helper. Any command-line arguments override thi"
                        "s config file as well."))
    VCFCmpParser.add_argument(
        "queryVCF", help="Query VCF to compare to reference VCF.",
        type=str)
    VCFCmpParser.add_argument(
        "--std", help="Reference VCF for comparing to query VCF.",
        type=str, required=True)
    VCFCmpParser.add_argument(
        "-o", "--outfile", help="Set output file path instead of stdout.")
    VCFCmpParser.add_argument(
        "--check-std",
        help=("If set, check standard VCF for calls in the query VCF rather "
              "than default behavior, which is checking the query VCF for "
              "calls that should be in the standard."),
        action="store_true")
    VCFCmpParser.add_argument(
        "--check-both", action="store_true",
        help=("If set, writes both set comparisons (std vs. query and query "
              "vs. standard) for filenames based on the input file name. "
              "Stdout not supported."))
    VCFCmpParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmfto"
                        "ols_helper. Any command-line arguments override thi"
                        "s config file as well."))
    GetUniqueKmerBedParser.add_argument(
        "--inbed", "-i",
        metavar="inbed",
        help=("Path to input bed file defining regions where we are "
              "interested in searching for unique kmers."),
        type=str,
        required=True)
    GetUniqueKmerBedParser.add_argument(
        "--ref", "-r",
        metavar="ref",
        help="Path to reference file. (Must be faidx'd)",
        type=str,
        required=True)
    GetUniqueKmerBedParser.add_argument(
        "--aligner", "-a",
        metavar="aligner",
        help="Aligner program (e.g. takes bwa 'mem' or bowtie 'bwt').",
        type=str,
        required=True)
    GetUniqueKmerBedParser.add_argument(
        "-k", "--kmer", help=("Length of unique sequence groups (kmers) "
                              "to search for in the reference."),
        metavar="kmer",
        type=int,
        required=True)
    GetUniqueKmerBedParser.add_argument(
        "-s", "--seed", help=("Seed length (for bowtie only)"),
        metavar="seed",
        type=int,
        required=False)
    GetUniqueKmerBedParser.add_argument(
        "--padding", "-p",
        help="Distance around the region of interest to pad.",
        type=int,
        required=True)
    GetUniqueKmerBedParser.add_argument(
        "--mismatches", "-m",
        metavar="mismatches",
        help="Number of allowed mismatches.",
        type=int,
        required=True)
    GetUniqueKmerBedParser.add_argument(
        "--outfile", "-o",
        metavar="outfile",
        help="Path to output bed file.",
        type=str,
        required=True)
    GetUniqueKmerBedParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmfto"
                        "ols_helper. Any command-line arguments override thi"
                        "s config file as well."))
    FamStatsParser = subparsers.add_parser(
        "famstats", description=("Generate family size stats for a "
                                 "flattened fastq file."))
    FamStatsParser.add_argument(
        "inFq", help="Path to flattened fastq file.", type=str)
    FamStatsParser.add_argument(
        "-o", "--outfile-handle", help="Path to output file. Default: stdout",
        type=argparse.FileType("w"))
    FamStatsParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmftoo"
                        "ls_helper. Any command-line arguments override this "
                        "config file as well."))
    InputQtyParser.add_argument(
        "-n", "--number-of-templates",
        help="Number of template molecules sequenced. "
        "(Both reads in a pair count as 1 total)",
        type=int, required=True)
    InputQtyParser.add_argument(
        "-p", "--paired",
        action="store_true",
        help="Set this flag if the data is paired-end.")
    InputQtyParser.add_argument(
        "-l", "--read-length",
        help="Length of each read.", type=int,
        required=True)
    InputQtyParser.add_argument(
        "--on-target", "-o",
        help="Fraction of reads which are on-target. Default: 0.25 (25%).",
        type=float)
    InputQtyParser.add_argument(
        "--region-size", "-s",
        help="Size of capture region in number of bases.",
        type=int, required=True)
    InputQtyParser.add_argument(
        "--FM", "-f",
        help="Desired mean family size.",
        required=True, type=float)
    InputQtyParser.add_argument(
        "--genome-size", "-g",
        help="Genome size for organism. Defaults to human genome length.",
        type=float)
    InputQtyParser.add_argument(
        "--no-strand-correction",
        help=("Whether or not to count copies of the genome by "
              "strand rather than by dsDNA."),
        action="store_true")
    InputQtyParser.add_argument(
        "--qc-fail",
        help="Fraction of reads not usable due to failing QC. Default: 0.1.",
        type=float)
    InputQtyParser.add_argument(
        "--mean-aligned-fraction",
        help=("Fraction of average read aligned. Default: 0.9"),
        type=float)
    InputQtyParser.add_argument(
        "--mapped-fraction",
        help=("Fraction of reads properly mapped with "
              "MQ != minMQ for variant-calling."),
        type=float)
    InputQtyParser.add_argument(
        "--ligation-efficiency",
        help="Efficiency of ligation of adapters.",
        type=float)
    InputQtyParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmftoo"
                        "ls_helper. Any command-line arguments override this "
                        "config file as well."))
    RescueShadingParser.add_argument(
        "-f", "--fastqs", help="Path to fastq files.",
        nargs="+", type=str)
    RescueShadingParser.add_argument(
        "--head",
        help=("Number of bases from each read with "
              "which to salt the barcode."),
        type=int)
    RescueShadingParser.add_argument(
        "--mm", help="Mismatch limit",
        type=int)
    RescueShadingParser.add_argument(
        "--minFam", "-m", help="Minimum family size for true families.",
        type=int)
    RescueShadingParser.add_argument(
        "--conf", help=("Path to a config file. If set, load arguments from "
                        "this file, overriding the defaults founds in _bmftoo"
                        "ls_helper. Any command-line arguments override this "
                        "config file as well."))
    BedCovParser.add_argument(
        "inBAM", help="Path to input BAM.")
    BedCovParser.add_argument(
        "--bed", "-b", help="Path to bed over which to calculate coverage.")
    BedCovParser.add_argument(
        "--threads", "-t", help="Number of threads to use.", type=int)
    BedCovParser.add_argument(
        "--FastDOCPath", "-p", help="Path to FastDOC executable jar.")
    BedCovParser.add_argument(
        "--conf", "-c", help=("Path to config file. Can be used in place of"
                              " any command line arguments."))
    BedCovParser.add_argument(
        "--bed-buffer",
        help=("Number of bases in each direction to pad the bed intervals for"
              " reads bleeding out into surrounding regions."),
        type=int)
    MainSubparser.add_argument(
        'fq',
        help="Provide your fastq file(s).",
        nargs="+",
        metavar=('reads'))
    MainSubparser.add_argument(
        "--indexFq",
        "-i",
        help="Path to index fastq",
        metavar="indexFastq")
    MainSubparser.add_argument(
        '--conf',
        help="Path to config file with settings.")
    MainSubparser.add_argument(
        '-s',
        '--single-end',
        help="Whether the experiment is single-end or not. Default: False",
        type=bool)
    MainSubparser.add_argument(
        '--homing',
        help="Homing sequence for samples.",
        metavar=('HomingSequence'))
    MainSubparser.add_argument(
        '--inline-barcodes',
        help="Use flag if using inline barcodes method.",
        action="store_true")
    MainSubparser.add_argument(
        '-a',
        '--aligner',
        help="Provide your aligner. Default: bwa",
        nargs='?',
        metavar='aligner')
    MainSubparser.add_argument(
        '-o',
        '--opts',
        help="Additional aligner opts. E.g.: --opts '-L 0' ")
    MainSubparser.add_argument(
        '-b',
        '--BAM',
        help="BAM file, if alignment has already run.")
    MainSubparser.add_argument(
        '--bed',
        help="full path to bed file used for variant-calling steps."
             "Can be indicated by the config file.",
        metavar="BEDFile")
    MainSubparser.add_argument(
        '-l',
        '--logfile',
        help="To change default logfile location.")
    MainSubparser.add_argument(
        '-p',
        '--file-prefix',
        help="Set non-default prefix.")
    MainSubparser.add_argument(
        '--minMQ',
        help="Minimum mapping quality for variant call inclusion. "
             "Can be indicated by the config file.",
        type=int)
    MainSubparser.add_argument(
        '--minBQ',
        help="Minimum base quality for variant call inclusion. "
             "Can be indicated by the config file.")
    MainSubparser.add_argument(
        "--minCov",
        help="Minimum coverage for including a position"
        " in the BamToCoverageBed")
    MainSubparser.add_argument(
        "--ref",
        "-r",
        help="Path to reference index. Can be indicated by the config file.")
    MainSubparser.add_argument(
        "--abrapath",
        help="Path to abra jar. Can be indicated by the config file.")
    MainSubparser.add_argument(
        "--p3Seq", help="3' primer sequence for cutadapt.")
    MainSubparser.add_argument(
        "--p5Seq", help="5' primer sequence for cutadapt.")
    MainSubparser.add_argument(
        "--review-dir", help="Prefix for review directory, where important re"
        "sults files will be moved at the end of analysis.")
    MainSubparser.add_argument("--minFA", help="Minimum family members agreed "
                               "on base for inclusion in variant call",
                               type=int)
    MainSubparser.add_argument("--picardpath", help="Path to picard jar. "
                               "Required for calling PicardTools.")
    MainSubparser.add_argument(
        "-g", "--realigner",
        help="Select which indel realigner you wish to use. Supported: abra, "
        "GATK. Set to None to avoid realignment.")
    MainSubparser.add_argument("--gatkpath", help="Path to GATK jar. (v1.6)")
    MainSubparser.add_argument("--readLength", help="Read length",
                               type=int)
    MainSubparser.add_argument("--experiment", "-e",
                               help="A comma-joined list of strings with "
                                    "extrainformation for informing "
                                    "analysis. Currently in beta support: "
                                    "ffpe, amplicon.")
    MainSubparser.add_argument(
        "--intelDeflator",
        help="Path to intel deflator. Speeds up abra calls.")
    MainSubparser.add_argument(
        "--sortMem",
        help="Memory to use for sorting fastq files. Default: 6G")
    MainSubparser.add_argument(
        "--bcLen",
        help=("Length of inline barcodes. Ignored for datasets where "
              "the molecular barcode is on a secondary index."),
        type=int)
    MainSubparser.add_argument(
        "--head", help=("Number of bases from the start of reads 1"
                        " and 2 to add to the barcode."),
        type=int)
    MainSubparser.add_argument(
        "--parallel",
        help="Parallelize variant calling activated by this flag.",
        action="store_true")
    MainSubparser.add_argument(
        "--rescue", type=str,
        help="Set to 'true' to add the rescue step to the family merging.")
    MainSubparser.add_argument(
        "--bwapath", help="Path to bwa executable. Default: bwa.")
    MergePairedAlignmentsParser.add_argument(
        "inBAM", help="Path to input BAM. Set to 'stdin' for stdin.")
    MergePairedAlignmentsParser.add_argument(
        "--outBAM", "-o",
        help=("Path to output BAM. Defaults to stdout. "
              "Set to stdout' to be explicit, otherwise."))
    MergePairedAlignmentsParser.add_argument(
        "--coorsort", "-s",
        help=("Use flag to turn on coordinate "
              "sort the merged pair bam output."),
        action="store_true")
    MergePairedAlignmentsParser.add_argument(
        "--conf", help="Path to config file for merging read pairs.")
    MergePairedAlignmentsParser.add_argument(
        "-u", "--uncompressed-bam",
        help="Flag to emit uncompressed bam.", action="store_true")
    MergePairedAlignmentsParser.add_argument(
        "-m", "--sortMem",
        help="sortMem string for sorting, if piping "
        "to a samtools sort. Default: 6G.")
    PEP8Parser.add_argument(
        "--dir",
        help="Path to directory from which to search "
        "recursively for .py/.pyx/.pxd files. Defaults to './'.",
        default="./")
    # for each subparser, add_argument for conf.
    # Load default one and then override with config file.
    # Then override any arguments that are not None.

    # set_trace()
    Palin = parser.parse_args()

    # Global Variables
    global Logger
    Logger = logging.getLogger("Primarylogger")
    global Chapman
    if(hasattr(Palin, "conf") is False):
        Palin.conf = None
    Chapman = ArgumentSketcher(Palin, Palin.conf)
    global Metrics
    Metrics = SampleMetrics()
    global ReviewDirFiles
    ReviewDirFiles = ReviewDirComponents()

    # BEGIN SETUP LOGGING #
    #
    # Declare logging style
    dateStr = datetime.datetime.now().strftime("%Y-%b-%d,%H-%m-%S")
    # Begin logging
    # Grabs first non "bmftools" and non-flag field.
    basename = "bmftools_%s" % Chapman('bmfsuites')
    logbasename = basename
    if(Chapman['logfile'] != "default"):
        logfile = Chapman['logfile']
    else:
        logfile = (os.getcwd() + "/" +
                   logbasename.split('.')[0] +
                   '.log')
    if(Chapman['file_prefix'] != "default"):
        logfile = os.getcwd() + "/" + Chapman['file_prefix'] + ".log"
    if(os.path.isfile(logfile)):
        logfile = TrimExt(logfile) + "." + \
                  str(uuid.uuid4().get_hex().upper()[0:6]) + ".log"

    # Logger which holds both console and file loggers
    Logger.setLevel(logging.DEBUG)

    # Console handler - outputs to console as stderr
    ch = logging.StreamHandler(stream=stderr)
    ch.setLevel(logging.DEBUG)

    # create formatter
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')

    # add formatter to ch
    ch.setFormatter(formatter)

    # add ch to logger
    Logger.addHandler(ch)

    # File logger - outputs to log file.

    # END SETUP LOGGING #

    print("All logging set up!")

    commandStr = " ".join(sys.argv)
    subcommand = Chapman['bmfsuites']
    if(subcommand in ["main", "snv", "psnv"] or
       Chapman['create_log'] is True):
        fl = logging.FileHandler(filename=logfile)
        fl.setFormatter(formatter)
        fl.setLevel(logging.DEBUG)
        Logger.addHandler(fl)
    else:
        stderr.write("Logging skipped for subcommand. Override with create_log"
                     " == True if you want to create a log next time.\n")
    stderr.write("Now executable bmftools subcommand %s" % subcommand)
    if(subcommand == "qty"):
        templatesOnTarget = Palin.number_of_templates * Palin.on_target
        if(Palin.paired):
            readsOnTarget = templatesOnTarget * 2
        else:
            readsOnTarget = templatesOnTarget
        basesOnTarget = (readsOnTarget * Palin.read_length *
                         (1 - Chapman['qc_fail']) *
                         Chapman['mean_aligned_fraction'] *
                         Chapman['mapped_fraction'] /
                         Chapman['ligation_efficiency'])
        # Ligation efficiency decreases diversity. Correct for this.
        genomeEquivalentsPerPg = 6.022e23 / (Chapman['genome_size'] * 1e15 *
                                             650 *
                                             Chapman['ligation_efficiency'])
        meanOnTargetCoverage = basesOnTarget / Chapman['region']
        NumCopiesDesired = meanOnTargetCoverage / Palin.FM
        DesiredInputQty = NumCopiesDesired / genomeEquivalentsPerPg
        if(not Palin.no_strand_correction):
            DesiredInputQty /= 2
        print("Desired input qty: %.8fpg" % DesiredInputQty)
    elif(subcommand == "psnv"):
        from utilBMF.HTSUtils import GetBMFsnvPopen, parseConfig
        from utilBMF.ErrorHandling import ThisIsMadness
        from subprocess import check_call
        import pysam
        from MawCluster import BCVCF
        from MawCluster.SNVUtils import GetVCFHeader
        if(Chapman['outVCF'] == "default"):
            outVCF = ".".join(Chapman['inBAM'].split(".")[0:-1] +
                              ["FULL", "bmf", "vcf"])
        else:
            outVCF = Chapman['outVCF']
        outHandle = open(outVCF, "w")
        outHandle.write(GetVCFHeader(
            commandStr=commandStr, reference=Chapman["ref"],
            header=pysam.AlignmentFile(Chapman['inBAM'], "rb").header))
        pl("Splitting BAM file by contig.")
        Dispatcher = GetBMFsnvPopen(Chapman['inBAM'], Chapman['bed'],
                                    conf=Chapman['conf'],
                                    threads=Chapman['threads'])
        if(Dispatcher.daemon() != 0):
            raise ThisIsMadness("Dispatcher failed somehow.")
        pl("Shell calls completed without errors.")
        for vcffile in Dispatcher.outstrs.values():
            check_call("cat %s >> %s" % (vcffile, outVCF), shell=True)
        pl("Filtering VCF by bed file. Pre-filter path: %s" % outVCF)
        bedFilteredVCF = BCVCF.FilterVCFFileByBed(
                    outVCF, bedfile=conf['bed'])
        pl("Filtered VCF: %s" % bedFilteredVCF)
        sys.exit(0)
    elif(subcommand == "snv"):
        from MawCluster.VCFWriters import SNVCrawler
        from utilBMF.HTSUtils import parseConfig
        from MawCluster.BCVCF import VCFStats
        if(Chapman['analysisTag'] != "default"):
            analysisTag = (Chapman['analysisTag'] + "-" +
                           "-".join([str(Chapman[i]) for i in
                                     ["minMQ", "minBQ", "minFA",
                                      "MaxPValue",
                                      "minFracAgreed"]]))
        else:
            analysisTag = "-".join([str(Chapman[i]) for i in
                                    ["minMQ", "minBQ", "minFA",
                                     "MaxPValue", "minFracAgreed"]])
        if(Chapman['outVCF'] == "default"):
            OutVCF = ".".join(Chapman['inBAM'].split(".")[0:-1] +
                              [analysisTag, "bmf", "vcf"])
        else:
            OutVCF = Chapman['outVCF']
        for pair in Chapman.iteritems():
            pl("Chapman entry. Key: %s. Value: %s." % (pair[0], pair[1]),
               level=logging.DEBUG)
        """
        import cProfile
        import pstats
        pr = cProfile.Profile()
        pr.enable()
        """

        if("bed" in Chapman.getkeys()):
            print("Reference: %s" % Chapman["ref"])
            # OutVCF = SNVCrawler(Chapman['inBAM'], **Chapman)
            OutVCF = SNVCrawler(Chapman['inBAM'],
                                bed=Chapman["bed"],
                                minMQ=Chapman["minMQ"],
                                minBQ=Chapman["minBQ"],
                                MaxPValue=Chapman["MaxPValue"],
                                keepConsensus=Chapman['keepConsensus'],
                                commandStr=commandStr,
                                reference=Chapman["ref"],
                                reference_is_path=True,
                                minFracAgreed=Chapman["minFracAgreed"],
                                minFA=Chapman["minFA"],
                                OutVCF=OutVCF,
                                writeHeader=(not Chapman['is_slave']))
            OutTable = VCFStats(OutVCF)
        else:
            OutVCF = SNVCrawler(Chapman['inBAM'],
                                minMQ=Chapman["minMQ"],
                                minBQ=Chapman["minBQ"],
                                MaxPValue=Chapman["MaxPValue"],
                                keepConsensus=Chapman['keepConsensus'],
                                commandStr=commandStr,
                                reference=Chapman["ref"],
                                reference_is_path=True,
                                minFracAgreed=Chapman["minFracAgreed"],
                                OutVCF=OutVCF,
                                minFA=Chapman["minFA"],
                                writeHeader=(not Chapman['is_slave']))
            OutTable = VCFStats(OutVCF)
        """
        import cStringIO
        s = cStringIO.StringIO()
        pr.disable()
        sortby = "cumulative"
        ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
        ps.print_stats()
        open("cProfile.stats.txt", "w").write(s.getvalue())
        """
        sys.exit(0)
    elif(subcommand == "vcfstats"):
        from MawCluster.BCVCF import VCFStats
        OutTable = VCFStats(Chapman['inVCF'])
        sys.exit(0)
    elif(subcommand == "dmp"):
        if(len(Chapman['inFqs']) == 2):
            from BMFMain.Workflow import pairedFastqShades
            OutFastq1, OutFastq2 = pairedFastqShades(
                Chapman['inFqs'][0],
                Chapman['inFqs'][1],
                indexFq=Chapman['indexFq'],
                p3Seq=Chapman['p3Seq'],
                p5Seq=Chapman['p5Seq'],
                rescue=Chapman['rescue'])
            return 0  # sys.exit(main()) returns 0
        elif(len(Chapman['inFqs']) == 1):
            from BMFMain.Workflow import singleFastqShades
            OutFastq = singleFastqShades(
                Chapman['inFqs'][0],
                indexFq=Chapman['indexFq'],
                p3Seq=Chapman['p3Seq'],
                p5Seq=Chapman['p5Seq'])
            return 0  # sys.exit(main()) returns 0
    elif(subcommand == "sv"):
        from utilBMF.ErrorHandling import ThisIsMadness
        from utilBMF.HTSUtils import FacePalm
        from MawCluster.TLC import BMFXLC as CallIntraTrans
        if(Chapman['bed'] == "default"):
            raise ThisIsMadness("Bed file required!")
        else:
            Output = CallIntraTrans(
                Chapman['bam'],
                outfile=Chapman['outTsv'],
                bedfile=Chapman['bed'],
                minMQ=Chapman['minMQ'],
                minBQ=Chapman['minBQ'],
                minClustDepth=Chapman['minClustDepth'],
                minPileupLen=Chapman['minPileupLen'],
                ref=Chapman['ref'],
                insDistance=Chapman['insert_distance'])
        return Output
    elif(subcommand == "sma"):
        from MawCluster import BCVCF
        Output = BCVCF.ISplitMultipleAlts(Chapman['inVCF'], Chapman['outVCF'])
        sys.exit(0)
    elif(subcommand == "vcfcmp"):
        from MawCluster.BCVCF import (CheckStdCallsForVCFCalls,
                                      CheckVCFForStdCalls)
        if(Chapman['check_both']):
            if(Chapman['outfile'] is None):
                Chapman['outfile'] = Chapman['queryVCF']
            StdForVCF = TrimExt(Chapman['outfile']) + ".VerifyCalls.vcf"
            VCFVsStd = (TrimExt(Chapman['outfile']) +
                        ".CheckForStdConcordance.vcf")
            CheckStdCallsForVCFCalls(Chapman['queryVCF'], Chapman['std'],
                                     outfile=StdForVCF)
            CheckVCFForStdCalls(Chapman['queryVCF'], std=Chapman['std'],
                                outfile=VCFVsStd)
            sys.exit(0)
        if(Chapman['check_std']):
            if(Chapman['outfile'] is not None):
                CheckStdCallsForVCFCalls(Chapman['queryVCF'],
                                         std=Chapman['std'],
                                         outfile=Chapman['outfile'])
            else:
                CheckStdCallsForVCFCalls(Chapman['queryVCF'],
                                         std=Chapman['std'],
                                         outfile=sys.stdout)
            sys.exit(0)
        if(Chapman['outfile'] is not None):
            CheckVCFForStdCalls(Chapman['queryVCF'], std=Chapman['std'],
                                outfile=Chapman['outfile'])
        else:
            CheckVCFForStdCalls(Chapman['queryVCF'], std=Chapman['std'],
                                outfile=sys.stdout)
        sys.exit(0)
    elif(subcommand == "getuniquekmersbed"):
        from utilBMF.Uniqueness import KmerFetcher
        from utilBMF.HTSUtils import ParseBed
        from subprocess import check_call
        if Chapman['aligner'] == 'bwt':
            raise ThisIsHKMadness("Bowtie not recommended for use due to "
                                  "identified bugs.")
        if Chapman['aligner'] == 'mem' and 'seed' in Chapman.getkeys():
            pl("WARNING: Bwa mem does not use the seed parameter, ignoring " +
               str(Chapman['seed']) + ".", level=logging.WARNING)
        pl("Grabbing regions in input bed file that contain uniquely mapping "
           "kmers.")
        # Loads unique kmers from each line of the (padded) bed file into a
        # KmerFetcher HashMap object (key=inbed region, value=list of RefKmer
        # objects) by running GetUniqueKmers (runs alignment on a fastq file
        # of kmers built from the padded bed regions & parses its output)
        KF = KmerFetcher(ref=Chapman['ref'], padding=Chapman['padding'],
                         mismatches=Chapman['mismatches'],
                         minMQ=Chapman['minMQ'], k=Chapman['kmer'],
                         aligner=Chapman['aligner'])

        bedlines = ParseBed(Chapman['inbed'])
        for bedlineList in bedlines:
            pl("Analyzing kmers from bed region " + bedlineList[0] + ": " +
               str(bedlineList[1]) + " - " + str(bedlineList[2]) +
               " with padding of " + str(Chapman['padding']))
            # Populate unique KmerObjects per region
            KF.FillMap(bedlineList)

        # Convert unique kmers to sorted/merged bedfile within the boundaries
        # of the original bed
        outList = KF.GetIntervalsFromMap()
        KF.ConvertIntervalsToBed(outList, inFile=Chapman['inbed'],
                                 outFile=Chapman['outfile'])

    elif(subcommand == "famstats"):
        from utilBMF.QC import GetFamSizeStats
        Stats = GetFamSizeStats(Chapman['inFq'],
                                outfile=Chapman['outfile_handle'])
    elif(subcommand == "v"):
        from utilBMF.HTSUtils import __version__
        print(__version__)
    elif(subcommand == "tagbam"):
        fastqs = Chapman['fastq']
        if(len(fastqs) == 1):
            singleBarcodeTagging(fastqs[0], Chapman['inBAM'],
                                 outputBAM=Chapman['outfile'])
        elif(len(fastqs) == 2):
            pairedBarcodeTagging(fastqs[0], fastqs[1], Chapman['inBAM'],
                                 outBAMFile=Chapman['outfile'])
    elif(subcommand == "aligntagbam"):
        from BMFMain.Workflow import pairedBamProc
        outBAM = pairedBamProc(
            Chapman['inFqs'][0],
            Chapman['inFqs'][1],
            ref=Chapman['ref'],
            bed=Chapman['bed'],
            aligner=Chapman['aligner'],
            realigner=Chapman['realigner'],
            abrapath=Chapman['abrapath'],
            rLen=Chapman['readLength'],
            gatkpath=Chapman['gatkpath'])
        pl("aligntagbam completed succesfully! Final bam is : " + outBAM)
        sys.exit(0)
    elif(subcommand == "rsq"):
        from BMFMain.Workflow import pairedFastqShades
        pairedFastqShades(Chapman['fastqs'][0],
                          Chapman['fastqs'][1],
                          indexFq=Chapman['fastqs'][2],
                          minFamRsq=Chapman['minFam'],
                          mmRsq=Chapman['mm'],
                          head=Chapman['head'], sortMem=Chapman['sortMem'],
                          rescue=True, p5Seq=Chapman['p5Seq'],
                          p3Seq=Chapman['p3Seq'])
    elif(subcommand == "bedcov"):
        # sys.stderr.write("config repr: %s" % repr(Chapman.config))
        from utilBMF.QC import FastDOCBed, ExtendBed
        if(Chapman['bed_buffer'] != 0):
            Chapman['bed'] = ExtendBed(Chapman['bed'],
                                       buffer=Chapman['bed_buffer'])
        pl("Buffering bed by %s" % Chapman['bed_buffer'])
        outbed, fracOnTarget = FastDOCBed(Chapman['inBAM'], bed=Chapman['bed'],
                                          threads=Chapman['threads'],
                                          FastDOCPath=Chapman['FastDOCPath'])
    elif(subcommand == "main"):
        print("Beginning something!")
        if(Chapman['single_end'] is True):
            pl("Single-end analysis chosen.")
            raise NotImplementedError("Single-end analysis not currently "
                                      "supported. Soon!")
        else:
            pl("Paired-end analysis chosen.")
            pl("Beginning fastq processing.")
            print("Repr of Chapman['fq']: %s" % repr(Chapman['fq']))
            trimfq1, trimfq2 = wf.pairedFastqShades(
                Chapman['fq'][0], Chapman['fq'][1],
                indexFq=Chapman['indexFq'],
                p3Seq=Chapman['p3Seq'], p5Seq=Chapman['p5Seq'],
                inline_barcodes=Chapman['inline_barcodes'],
                homing=Chapman['homing'],
                bcLen=Chapman['bcLen'], head=Chapman['head'],
                rescue=Chapman['rescue'],
                sortMem=Chapman['sortMem'])
            procSortedBam = wf.pairedBamProc(
                trimfq1, trimfq2,
                aligner=Chapman['aligner'], ref=Chapman['ref'],
                bed=Chapman['bed'],
                abrapath=Chapman['abrapath'],
                picardpath=Chapman['picardpath'],
                dbsnp=Chapman['dbsnp'],
                gatkpath=Chapman['gatkpath'],
                realigner=Chapman('realigner'),
                rLen=Chapman['readLength'],
                opts=Chapman['opts'],
                kmers_precomputed=Chapman['kmers_precomputed'],
                intelDeflator=Chapman['intelDeflator'],
                sortMem=Chapman['sortMem'],
                bwapath=Chapman['bwapath'])
            VCFOutDict = wf.pairedVCFProc(
                procSortedBam,
                ref=Chapman['ref'],
                opts=Chapman['opts'],
                bed=Chapman['bed'],
                minMQ=Chapman['minMQ'],
                minBQ=Chapman['minBQ'],
                commandStr=" ".join(sys.argv),
                minFA=Chapman['minFA'], minFracAgreed=Chapman['minFracAgreed'],
                exp=Chapman['experiment'], conf=Chapman['conf'],
                parallel=Chapman['parallel'])
            QCMetrics = GetAllQCMetrics(procSortedBam, bedfile=Chapman['bed'],
                                        minFM=Chapman['minFM'],
                                        FastDOCPath=Chapman["FastDOCPath"],
                                        minMQ=Chapman("minMQ"))
            pl("Last stop! Watch your step.")
    if(subcommand == "mpa"):
        from utilBMF.MPA import MPA2Bam
        if(Chapman('outBAM') in [None, "default", "stdout"]):
            Chapman['outBAM'] = "-"  # Prints to stdout.
        outBAM = MPA2Bam(Chapman['inBAM'], outBAM=Chapman['outBAM'],
                         u=Chapman('uncompressed_bam'),
                         coorsort=Chapman('coorsort'),
                         sortMem=Chapman('sortMem'))
    if(subcommand == "pep8"):
        from subprocess import Popen, PIPE
        from time import sleep
        if(os.path.isdir(Chapman['dir']) is False):
            raise ImproperArgumentError(
                "Directory %s is not a directory. Abort!" % Chapman['dir'])
        cStr = ("pep8 $(find " + Chapman['dir'] +
                " -name '*.pyx' -o -name '*.pxd' -o -name '*.py')" +
                "| grep -v \"missing whitespace\|module level\"")
        complaints = Popen(cStr, shell=True, stdout=PIPE)
        count = 0
        while count < 600:
            if(complaints.poll() is not None):
                break
            sleep(0.5)
        out, err = complaints.communicate()
        if(len(out) == 0):
            pl("No modified pep8 violations. Congrats!")
            return 0
        else:
            pl("Violations found! Consider either changing your modified "
               "standards or caring more about these violations.")
            sys.stdout.write(out)
            return 1
    if(subcommand == "pipetagbam"):
        from MawCluster.BCBam import PipeBarcodeTagCOBam
        compressInput = True if(
            Palin.compression[0] == 'b') else False
        bamOutput = True if(
            Palin.compression[1] == 'b') else False
        uncompressed_output = (True if(
            'u' in Palin.compression) else False)
        pl("Now piping %s input to %s output" % ("bam" if(
            compressInput) else "sam",
                                                 "bam" if(
            bamOutput) else "sam"))
        PipeBarcodeTagCOBam()
    pl("Successful completion of subcommand %s." % subcommand +
       "\nSample Metrics: %s" % repr(Metrics))
    return 0

if(__name__ == "__main__"):
    sys.exit(main())
